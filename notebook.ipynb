{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample code to generate test cases and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have external objects (non in-built python objects) as input/output in our functions/methods. Here is how you need to configure the module before trying to get the test cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add custom type handlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logitest import get_dtype, add_to_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom load and dump functions\n",
    "\n",
    "import fitz\n",
    "\n",
    "def load_pdf(filepath):\n",
    "    doc = fitz.open(filepath)\n",
    "    return doc\n",
    "\n",
    "dump_pdf = lambda doc, filepath: doc.save(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pymupdf.Document'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To know the datatype of the object, load a sample object and check like this:\n",
    "\n",
    "doc = load_pdf(\"C:/Users/samoj/Downloads/COA requirements.pdf\")\n",
    "# doc = load_pdf(\"./COA requirements.pdf\")\n",
    "\n",
    "get_dtype(doc) # This will be used as the key for your new_type_handlers dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, create a type handling dictionary as shown below\n",
    "# Note: This new dictionary should have the name 'new_type_handlers'\n",
    "\n",
    "new_type_handlers = {\n",
    "    \"pymupdf.Document\": {\n",
    "        \"extension\": \".npy\", \n",
    "        \"load\": load_pdf, \n",
    "        \"dump\": dump_pdf\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now add the entire code in a triple string, like this:\n",
    "\n",
    "type_handler_str = \"\"\"import fitz\n",
    "\n",
    "def load_pdf(filepath):\n",
    "    doc = fitz.open(filepath)\n",
    "    return doc\n",
    "\n",
    "dump_pdf = lambda doc, filepath: doc.save(filepath)\n",
    "\n",
    "new_type_handlers = {\n",
    "    \"pymupdf.Document\": {\n",
    "        \"extension\": \".npy\", \n",
    "        \"load\": load_pdf, \n",
    "        \"dump\": dump_pdf\n",
    "    }\n",
    "}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add custom Assertion mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have any custom assert functions to load, follow this process\n",
    "\n",
    "# First create your custom assert function\n",
    "\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "def assert_documents_equal(doc1_path, doc2_path, tolerance=0):\n",
    "    doc1 = fitz.open(doc1_path)\n",
    "    doc2 = fitz.open(doc2_path)\n",
    "\n",
    "    if len(doc1) != len(doc2):\n",
    "        raise AssertionError(f\"Documents have different number of pages: {len(doc1)} != {len(doc2)}\")\n",
    "\n",
    "    for page_num in range(len(doc1)):\n",
    "        pix1 = doc1[page_num].get_pixmap()\n",
    "        pix2 = doc2[page_num].get_pixmap()\n",
    "\n",
    "        if pix1.size != pix2.size or pix1.samples != pix2.samples:\n",
    "            diff = sum(\n",
    "                abs(a - b)\n",
    "                for a, b in zip(pix1.samples, pix2.samples)\n",
    "            )\n",
    "            if diff > tolerance:\n",
    "                raise AssertionError(\n",
    "                    f\"Page {page_num + 1} differs beyond tolerance level {tolerance}. \"\n",
    "                    f\"Difference: {diff}.\"\n",
    "                )\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new assertion mapping dictionary\n",
    "# Note, the name of this dictionary should new_assertion_mapping\n",
    "\n",
    "new_assertion_mapping = {\"pymupdf.Document\": ( # key is as usual the object it can test\n",
    "    \"from logitest.config import assert_documents_equal\", # standard import statement to import the custom function\n",
    "    \"assert_documents_equal\" # custom function name\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now add this entire code in triple quotes like this:\n",
    "\n",
    "assertion_mapping_str = \"\"\"import fitz  # PyMuPDF\n",
    "\n",
    "def assert_documents_equal(doc1_path, doc2_path, tolerance=0):\n",
    "    doc1 = fitz.open(doc1_path)\n",
    "    doc2 = fitz.open(doc2_path)\n",
    "\n",
    "    if len(doc1) != len(doc2):\n",
    "        raise AssertionError(f\"Documents have different number of pages: {len(doc1)} != {len(doc2)}\")\n",
    "\n",
    "    for page_num in range(len(doc1)):\n",
    "        pix1 = doc1[page_num].get_pixmap()\n",
    "        pix2 = doc2[page_num].get_pixmap()\n",
    "\n",
    "        if pix1.size != pix2.size or pix1.samples != pix2.samples:\n",
    "            diff = sum(\n",
    "                abs(a - b)\n",
    "                for a, b in zip(pix1.samples, pix2.samples)\n",
    "            )\n",
    "            if diff > tolerance:\n",
    "                raise AssertionError(\n",
    "                    f\"Page {page_num + 1} differs beyond tolerance level {tolerance}. \"\n",
    "                    f\"Difference: {diff}.\"\n",
    "                )\n",
    "    return True\n",
    "\n",
    "new_assertion_mapping = {\"pymupdf.Document\": (\"from logitest.config import assert_documents_equal\", \"assert_documents_equal\")}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding custom code to config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Added custom code to config'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The final line for configuring the module\n",
    "\n",
    "add_to_config(type_handling_str=type_handler_str, assertion_mapping_str=assertion_mapping_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and run tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created conftest.py at d:\\CodeWork\\GitHub\\logitest\\examples\\conftest.py\n",
      "\n",
      "Running tests with coverage...\n",
      "\n",
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "platform win32 -- Python 3.9.0, pytest-8.3.3, pluggy-1.5.0\n",
      "rootdir: d:\\CodeWork\\GitHub\\logitest\n",
      "plugins: cov-6.0.0\n",
      "collected 23 items\n",
      "\n",
      "tests\\file1\\test_add.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                         [ 34%]\u001b[0m\n",
      "tests\\file1\\test_subtract.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                       [ 56%]\u001b[0m\n",
      "tests\\file2\\test_divide.py \u001b[32m.\u001b[0m\u001b[32m                                             [ 60%]\u001b[0m\n",
      "tests\\file2\\test_multiply.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                          [ 69%]\u001b[0m\n",
      "tests\\file3\\test_calc.py \u001b[32m.\u001b[0m\u001b[32m                                               [ 73%]\u001b[0m\n",
      "tests\\file4\\test_data_preprocessor.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                             [100%]\u001b[0m\n",
      "\n",
      "----------- coverage: platform win32, python 3.9.0-final-0 -----------\n",
      "Name                                    Stmts   Miss  Cover   Missing\n",
      "---------------------------------------------------------------------\n",
      "conftest.py                                 3      0   100%\n",
      "example_module\\__init__.py                  0      0   100%\n",
      "example_module\\file1.py                     9      0   100%\n",
      "example_module\\file2.py                     6      0   100%\n",
      "example_module\\file3.py                     4      0   100%\n",
      "example_module\\file4.py                    18      0   100%\n",
      "main.py                                    19     19     0%   1-22\n",
      "tests\\file1\\__init__.py                     0      0   100%\n",
      "tests\\file1\\test_add.py                    60      0   100%\n",
      "tests\\file1\\test_subtract.py               42      0   100%\n",
      "tests\\file2\\__init__.py                     0      0   100%\n",
      "tests\\file2\\test_divide.py                 18      0   100%\n",
      "tests\\file2\\test_multiply.py               24      0   100%\n",
      "tests\\file3\\__init__.py                     0      0   100%\n",
      "tests\\file3\\test_calc.py                   18      0   100%\n",
      "tests\\file4\\__init__.py                     0      0   100%\n",
      "tests\\file4\\test_data_preprocessor.py      85      0   100%\n",
      "---------------------------------------------------------------------\n",
      "TOTAL                                     306     19    94%\n",
      "\n",
      "\n",
      "\u001b[32m============================= \u001b[32m\u001b[1m23 passed\u001b[0m\u001b[32m in 4.15s\u001b[0m\u001b[32m ==============================\u001b[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally to create the test cases for your code\n",
    "\n",
    "from logitest import create_test_cases\n",
    "\n",
    "# Pass your module directory path and main.py which uses this code to run your module pipeline\n",
    "create_test_cases(module_dirpath = \"examples/example_module\", main_filepath=\"examples/main.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
